{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb0cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Final Submission Notebook for CMI Kaggle Competition.\n",
    "This notebook integrates the trained model and the finalized feature engineering\n",
    "function within the required Kaggle API loop structure.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data.kaggle_evaluation\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd88b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import PROJECT_PATH, DATA_PATH\n",
    "from src.feature_engineering import create_wave1_features\n",
    "TEST_DATA_FILE = 'test.csv'\n",
    "TEST_DEMOGRAPHICS_FILE = 'test_demographics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a98a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Update these paths to where you save your final model and feature function ---\n",
    "MODEL_PATH = 'models_rev/wave1-catboost-best.cbm'\n",
    "FEATURE_FUNCTION_NAME = 'create_wave1_features' # Name of the final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc9a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gesture Map: {'Cheek - pinch skin': 0, 'Forehead - pull hairline': 1, 'Write name on leg': 2, 'Feel around in tray and pull out an object': 3, 'Neck - scratch': 4, 'Neck - pinch skin': 5, 'Eyelash - pull hair': 6, 'Eyebrow - pull hair': 7, 'Forehead - scratch': 8, 'Above ear - pull hair': 9, 'Wave hello': 10, 'Write name in air': 11, 'Text on phone': 12, 'Pull air toward your face': 13, 'Pinch knee/leg skin': 14, 'Scratch knee/leg skin': 15, 'Drink from bottle/cup': 16, 'Glasses on/off': 17}\n",
      "\n",
      "Inverted Gesture Map: {0: 'Cheek - pinch skin', 1: 'Forehead - pull hairline', 2: 'Write name on leg', 3: 'Feel around in tray and pull out an object', 4: 'Neck - scratch', 5: 'Neck - pinch skin', 6: 'Eyelash - pull hair', 7: 'Eyebrow - pull hair', 8: 'Forehead - scratch', 9: 'Above ear - pull hair', 10: 'Wave hello', 11: 'Write name in air', 12: 'Text on phone', 13: 'Pull air toward your face', 14: 'Pinch knee/leg skin', 15: 'Scratch knee/leg skin', 16: 'Drink from bottle/cup', 17: 'Glasses on/off'}\n",
      "\n",
      "Gesture To Sequence Type: {'Cheek - pinch skin': 'Target', 'Forehead - pull hairline': 'Target', 'Write name on leg': 'Non-Target', 'Feel around in tray and pull out an object': 'Non-Target', 'Neck - scratch': 'Target', 'Neck - pinch skin': 'Target', 'Eyelash - pull hair': 'Target', 'Eyebrow - pull hair': 'Target', 'Forehead - scratch': 'Target', 'Above ear - pull hair': 'Target', 'Wave hello': 'Non-Target', 'Write name in air': 'Non-Target', 'Text on phone': 'Non-Target', 'Pull air toward your face': 'Non-Target', 'Pinch knee/leg skin': 'Non-Target', 'Scratch knee/leg skin': 'Non-Target', 'Drink from bottle/cup': 'Non-Target', 'Glasses on/off': 'Non-Target'}\n"
     ]
    }
   ],
   "source": [
    "#GLOBAL MAPS\n",
    "# Load training data\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df_train_demos = pd.read_csv(os.path.join(DATA_PATH, 'train_demographics.csv'))\n",
    "\n",
    "# --- Create Helper Mappings for Evaluation Metric ---\n",
    "# Important for the custom F1 score function\n",
    "metadata = df_train[['gesture', 'sequence_type']].drop_duplicates()\n",
    "\n",
    "# Map gesture string to sequence type (Target vs. Non-Target)\n",
    "gesture_to_seq_type_map = metadata.set_index('gesture')['sequence_type'].to_dict()\n",
    "\n",
    "# Map gesture string to integer code and back\n",
    "gesture_map = {label: i for i, label in enumerate(metadata['gesture'].unique())}\n",
    "inv_gesture_map = {i: label for label, i in gesture_map.items()}\n",
    "\n",
    "# Validate\n",
    "print(f\"Gesture Map: {gesture_map}\")\n",
    "print(f\"\\nInverted Gesture Map: {inv_gesture_map}\")\n",
    "print(f\"\\nGesture To Sequence Type: {gesture_to_seq_type_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0550b6",
   "metadata": {},
   "source": [
    "## Load model and feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb2ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: {'nan_mode': 'Min', 'gpu_ram_part': 0.95, 'eval_metric': 'MultiClass', 'iterations': 1000, 'leaf_estimation_method': 'Newton', 'observations_to_bootstrap': 'TestOnly', 'od_pval': 0, 'random_score_type': 'NormalWithModelSizeDecrease', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.1000000015, 'devices': '-1', 'eval_fraction': 0, 'pinned_memory_bytes': '104857600', 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'od_type': 'Iter', 'rsm': 1, 'boost_from_average': False, 'gpu_cat_features_storage': 'GpuRam', 'fold_size_loss_normalization': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'use_best_model': True, 'meta_l2_frequency': 0, 'od_wait': 50, 'class_names': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], 'random_seed': 42, 'depth': 6, 'border_count': 128, 'min_fold_size': 100, 'data_partition': 'DocParallel', 'bagging_temperature': 1, 'classes_count': 0, 'auto_class_weights': 'None', 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'min_data_in_leaf': 1, 'add_ridge_penalty_to_loss_function': False, 'loss_function': 'MultiClass', 'learning_rate': 0.05000000075, 'meta_l2_exponent': 1, 'score_function': 'Cosine', 'task_type': 'GPU', 'leaf_estimation_iterations': 1, 'bootstrap_type': 'Bayesian', 'max_leaves': 64}\n",
      "\n",
      "Model classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "source": [
    "model = cat.CatBoostClassifier()\n",
    "model.load_model(MODEL_PATH);\n",
    "print(f\"Model parameters: {model.get_all_params()}\")\n",
    "print(f\"\\nModel classes: {model.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e14aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_submission_features(single_sequence_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Final feature engineering function for submission using Wave 1 logic.\n",
    "    This function:\n",
    "    1. Takes a single pandas DataFrame (e.g., `test_sequence_df` from the API).\n",
    "    2. Calls the modular `create_wave1_features` function.\n",
    "    \n",
    "    Note: create_wave1_features processes one sequence_id but expects a df with 'sequence_id'.\n",
    "    The API provides data for one sequence_id, so we need to ensure it's handled correctly.\n",
    "    The function groups by 'sequence_id', so it should work on the slice provided by the API.\n",
    "    \n",
    "    3. Post-processes the result to return a single-row DataFrame of features.\n",
    "    4. Ensures 'sequence_id' column is present for later dropping.\n",
    "    5. Handles -1.0 in ToF columns correctly (should be handled inside `create_wave1_features`).\n",
    "    \"\"\"\n",
    "    print(f\"  [Feature Eng.] Processing sequence data of shape {single_sequence_df.shape}...\")\n",
    "    \n",
    "    # --- Proactive State Management: Validate Input ---\n",
    "    required_base_cols = ['sequence_id', 'phase', 'subject', 'acc_x', 'acc_y', 'acc_z',\n",
    "                          'rot_w', 'rot_x', 'rot_y', 'rot_z', 'thm_1', 'thm_2',\n",
    "                          'thm_3', 'thm_4', 'thm_5', 'sequence_counter']\n",
    "    # Check for ToF columns\n",
    "    tof_cols_exist = any(col.startswith('tof_') for col in single_sequence_df.columns)\n",
    "    if not tof_cols_exist:\n",
    "        raise ValueError(\"No ToF columns (starting with 'tof_') found in API-provided data.\")\n",
    "    missing_base_cols = [col for col in required_base_cols if col not in single_sequence_df.columns]\n",
    "    if missing_base_cols:\n",
    "        raise ValueError(f\"Missing required base columns for Wave 1 feature engineering: {missing_base_cols}\")\n",
    "    \n",
    "    # Call feature engineering function from src.feature_engineering\n",
    "    # The function will group by 'sequence_id' to produce one output row.abs\n",
    "    try:\n",
    "        # This function is expected to handle -1.0 in ToF internally.\n",
    "        features_df = create_wave1_features(single_sequence_df)\n",
    "        print(f\"  [Feature Eng.] FE function returned shape: {features_df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [Feature Eng.] Error in modular function: {e}\")\n",
    "        raise e\n",
    "    \n",
    "    \n",
    "    # Post processing - ensure the output is a single row DF\n",
    "    if not isinstance(features_df, pd.DataFrame):\n",
    "        raise  TypeError(\"Modular feature function must return a pandas Dataframe!\")\n",
    "    if len(features_df) != 1:\n",
    "        raise ValueError(f\"Modular feature function should return 1 row, got {len(features_df)}.\")\n",
    "    \n",
    "    \n",
    "    # Ensure sequence_id is present (will be dropped later)\n",
    "    if 'sequence_id' not in features_df.columns:\n",
    "        # Get sequence_id from the input data (assuming it is consistent)\n",
    "        seq_id_from_input = single_sequence_df['sequence_id'].iloc[0]\n",
    "        features_df['sequence_id'] = seq_id_from_input\n",
    "        print(f\"  [Feature Eng.] Added missing 'sequence_id' column with value {seq_id_from_input}.\")\n",
    "        \n",
    "    print(f\"  [Feature Eng.] Final features ready. Shape: {features_df.shape}\")\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02806f",
   "metadata": {},
   "source": [
    "## Submission loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98d6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7b02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b591867b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
