{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fade942b",
   "metadata": {},
   "source": [
    "# Iterating, Tuning Hyper-Parameters and Testing Advanced Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0480f",
   "metadata": {},
   "source": [
    "## Key Revisions to the Strategic Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b473e",
   "metadata": {},
   "source": [
    "1. Feature Engineering Becomes a Cycle of Creation and Pruning\n",
    "\n",
    "2. Robust, API-Ready Validation is Non-Negotiable.\n",
    "\n",
    "3. Targeted, Metric-Driven Hyperparameter Tuning.\n",
    "\n",
    "4. Modular, Interpretable Code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e89adc",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096259a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEMPORARY\n",
    "import sys\n",
    "sys.path.append('/home/bac/code/kaggle/kaggle-cmi-detect-behavior/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b5f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import catboost as cat\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# --- Pathing and Experiment Tracking Setup ---\n",
    "from src.tracking import ExperimentTracker\n",
    "from src.config import DATA_PATH, PROJECT_PATH, USE_WANDB, WANDB_PROJECT, WANDB_ENTITY\n",
    "\n",
    "tracker = ExperimentTracker(\n",
    "    project_path=os.path.expanduser(PROJECT_PATH),\n",
    "    use_wandb=USE_WANDB,\n",
    "    wandb_project_name=WANDB_PROJECT,\n",
    "    wandb_entity=WANDB_ENTITY\n",
    ")\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa96ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data and create helper maps\n",
    "train_sensor = pd.read_csv(os.path.join(os.path.expanduser(DATA_PATH), 'train.csv'))\n",
    "train_demos = pd.read_csv(os.path.join(os.path.expanduser(DATA_PATH), 'train_demographics.csv'))\n",
    "train_df = pd.merge(train_sensor, train_demos, on='subject', how='left')\n",
    "metadata = train_df[['gesture', 'sequence_type']].drop_duplicates()\n",
    "gesture_to_seq_type_map = metadata.set_index('gesture')['sequence_type'].to_dict()\n",
    "gesture_map = {label: i for i, label in enumerate(metadata['gesture'].unique())}\n",
    "inv_gesture_map = {i: label for label, i in gesture_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c32fe2",
   "metadata": {},
   "source": [
    "## Pipeline Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2aa99e",
   "metadata": {},
   "source": [
    "Major components which have been used to train the model baseline thusfar will be encapsulated in modular code.\n",
    "\n",
    "1. Wave 4 feature generation\n",
    "2. Competition metric\n",
    "3. Model Training\n",
    "\n",
    "**`NOTE` the model generates inconsistencies in the code following a strategic review. These errors need to be reviewed!! At present, these were spotted in the `create_wave4_features()` function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbbf65",
   "metadata": {},
   "source": [
    "```python\n",
    "def create_wave4_features(df):\n",
    "    \"\"\"\n",
    "    Creates Wave-4 features: Adds demographic features to Wave 3a-PCA\n",
    "    feature set.\n",
    "    \"\"\"\n",
    "    \n",
    "    ...\n",
    "    for col in base_cols_to_agg + derived_cols_to_agg + tof_derived_cols_to_agg:\n",
    "        aggs[col] = ['mean', 'std', 'min', 'max'] # FLAG\n",
    "\n",
    "    phase_agg_df = df_feat.groupby(['sequence_id', 'phase']).agg(aggs)\n",
    "    phase_agg_df.columns = ['_'.join(col).strip() for col in phase_agg_df.columns.values]\n",
    "    phase_agg_df_unstacked = phase_agg_df.unstack(level='phase') # FLAG FILLNA\n",
    "    phase_agg_df_unstacked.columns = ['_'.join(col).strip() for col in phase_agg_df_unstacked.columns.values]\n",
    "    \n",
    "    meta_df = df.groupby('sequence_id').first()\n",
    "    final_df = pd.concat([meta_df[['subject', 'gesture'] + list(train_demos.columns[1:])], phase_agg_df_unstacked], axis=1).reset_index()\n",
    "    \n",
    "    # Create interaction features\n",
    "    key_sensor_features = [\n",
    "        'acc_mag_mean_Gesture', 'acc_mag_std_Gesture', 'jerk_mean_Gesture',\n",
    "        'jerk_std_Gesture', 'tof_pca_0_mean_Gesture', 'tofl_invalid_pct_mean_Gesture'\n",
    "    ]\n",
    "    demographic_features = ['age', 'height_cm', 'shoulder_to_wrist_cm'] # flag\n",
    "    \n",
    "    for sensor_feat in key_sensor_features:\n",
    "        for demo_feat in demographic_features:\n",
    "            if sensor_feat in final_df.columns and demo_feat in final_df.columns:\n",
    "                # Interaction by division (normalizing sensor reading by demographic)\n",
    "                final_df[f'{sensor_feat}_div_{demo_feat}'] = final_df[sensor_feat] / (final_df[demo_feat] + 1e-6)\n",
    "                # Ineraction by multiplication\n",
    "                final_df[f'{sensor_feat}_mul_{demo_feat}'] = final_df[sensor_feat] * final_df[demo_feat]\n",
    "    \n",
    "    #final_df.drop(columns='subject', inplace=True)\n",
    "    final_df['gesture_encoded'] = final_df['gesture'].map(gesture_map)\n",
    "    \n",
    "    print(f\"Feature engineering complete. Shape of features: {final_df.shape}\")\n",
    "    return final_df\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wave4n_features(df):\n",
    "    \"\"\"\n",
    "    Creates Wave-4 features: Adds demographic features to Wave 3a-PCA\n",
    "    feature set. With slight modifications below.\n",
    "    \"\"\"\n",
    "    print(\"Starting Wave 4 (Interaction) Feature Engineering...\")\n",
    "    df_feat = df.copy()\n",
    "    df_feat['acc_mag'] = np.sqrt(df_feat['acc_x']**2 + df_feat['acc_y']**2 + df_feat['acc_z']**2)\n",
    "    df_feat['rot_mag'] = np.sqrt(df_feat['rot_w']**2 + df_feat['rot_x']**2 + df_feat['rot_y']**2 + df_feat['rot_z']**2)\n",
    "    df_feat['jerk'] = df_feat.groupby('sequence_id')['acc_mag'].diff().fillna(0)\n",
    "    for i in range(1, 5): \n",
    "        df_feat[f'thm_grad_{i}_{i+1}'] = df_feat[f'thm_{i}'] - df_feat[f'thm_{i+1}']\n",
    "    \n",
    "    tof_cols = [f'tof_{s}_v{p}' for s in range(1, 6) for p in range(64)]\n",
    "    tof_data = df_feat[tof_cols].replace(-1, np.nan)\n",
    "    df_feat['tof_invalid_pct'] = tof_data.isna().mean(axis=1)\n",
    "    \n",
    "    pca = PCA(n_components=10, random_state=SEED) \n",
    "    tof_pca_features = pca.fit_transform(tof_data.fillna(0))\n",
    "    for i in range(10): \n",
    "        df_feat[f'tof_pca_{i}'] = tof_pca_features[:, i]\n",
    "        \n",
    "    base_cols_to_agg = [col for col in df.columns if 'acc_' in col or 'rot_' in col or 'thm_' in col]\n",
    "    derived_cols_to_agg = [col for col in df_feat.columns if 'mag' in col or 'jerk' in col or 'grad' in col]\n",
    "    tof_derived_cols_to_agg = ['tof_invalid_pct'] + [f'tof_pca_{i}' for i in range(10)]\n",
    "    aggs = {}\n",
    "    for col in base_cols_to_agg + derived_cols_to_agg: \n",
    "        aggs[col] = ['mean', 'std', 'min', 'max', 'skew'] # FLAG\n",
    "    for col in tof_derived_cols_to_agg:\n",
    "        aggs[col] = ['mean', 'std', 'min', 'max'] # FLAG\n",
    "        \n",
    "    phase_agg_df = df_feat.groupby(['sequence_id', 'phase']).agg(aggs)\n",
    "    phase_agg_df.columns = ['_'.join(col).strip() for col in phase_agg_df.columns.values]\n",
    "    phase_agg_df_unstacked = phase_agg_df.unstack(level='phase').fillna(0) # FLAG\n",
    "    phase_agg_df_unstacked.columns = ['_'.join(col).strip() for col in phase_agg_df_unstacked.columns.values]\n",
    "    \n",
    "    meta_df = df.groupby('sequence_id').first()\n",
    "    final_df = pd.concat([meta_df[['gesture'] + list(train_demos.columns)], phase_agg_df_unstacked], axis=1).reset_index()\n",
    "    \n",
    "    key_sensor_features = ['acc_mag_mean_Gesture', 'acc_mag_std_Gesture', 'jerk_mean_Gesture', \n",
    "                           'jerk_std_Gesture', 'tof_pca_0_mean_Gesture', 'tof_invalid_pct_mean_Gesture']\n",
    "    demographic_features = ['age', 'height_cm', 'shoulder_to_wrist_cm', 'sex', 'elbow_to_wrist_cm'] # FLAG\n",
    "    for sensor_feat in key_sensor_features:\n",
    "        for demo_feat in demographic_features:\n",
    "            if sensor_feat in final_df.columns and demo_feat in final_df.columns:\n",
    "                final_df[f'{sensor_feat}_div_{demo_feat}'] = final_df[sensor_feat] / (final_df[demo_feat] + 1e-6)\n",
    "                final_df[f'{sensor_feat}_mul_{demo_feat}'] = final_df[sensor_feat] * final_df[demo_feat]\n",
    "                \n",
    "    final_df['gesture_encoded'] = final_df['gesture'].map(gesture_map)\n",
    "    print(f\"Feature engineering complete. Shape of features: {final_df.shape}\")\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0205b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_f1_score(y_true_encoded, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Calculates the official competition F1 score.\n",
    "    \n",
    "    Args:\n",
    "        y_true_encoded: True labels, integer encoded.\n",
    "        y_pred_proba: Predicted probabilities from the model.\n",
    "    \"\"\"\n",
    "    # Get predicted labels by finding the class with the highest probability\n",
    "    y_pred_encoded = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    # Map integer-encoded labels back to the string representations\n",
    "    y_true_str = pd.Series(y_true_encoded).map(inv_gesture_map)\n",
    "    y_pred_str = pd.Series(y_pred_encoded).map(inv_gesture_map)\n",
    "    \n",
    "    # Binary F1\n",
    "    y_true_binary = y_true_str.map(gesture_to_seq_type_map)\n",
    "    y_pred_binary = y_true_str.map(gesture_to_seq_type_map)\n",
    "    binary_f1 = f1_score(y_true_binary, y_pred_binary, pos_label='Target', average='binary')\n",
    "    \n",
    "    # Macro F1 (collaped non-target class)\n",
    "    def collapse_non_target(gesture):\n",
    "        return 'non_target' if gesture_to_seq_type_map[gesture] == 'Non-Target' else gesture\n",
    "    \n",
    "    y_true_collapsed = y_true_str.apply(collapse_non_target)\n",
    "    y_pred_collapsed = y_pred_str.apply(collapse_non_target)\n",
    "    macro_f1 = f1_score(y_true_collapsed, y_pred_collapsed, average='macro')\n",
    "    \n",
    "    # Final score = average of the two components\n",
    "    return (binary_f1 + macro_f1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40099d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Trains a CatBoost model and returns the trained object.\"\"\"\n",
    "    model = cat.CatBoostClassifier(\n",
    "        iterations=1000, learning_rate=0.05, depth=6,\n",
    "        loss_function='MultiClass', eval_metric='MultiClass',\n",
    "        random_seed=SEED, verbose=0\n",
    "    )\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100)\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_feature_importance(model, feature_names, top_n=50):\n",
    "    \"\"\"Plots feature importance from a trained CatBoost model\"\"\"\n",
    "    imp_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': model.get_feature_importance()\n",
    "    }).sort_values('importance', ascending=False).head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(10, top_n / 2))\n",
    "    sns.barplot(x='importance', y='feature', data=imp_df)\n",
    "    plt.title(f'Top {top_n} Features (CatBoost Built-in Importance)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return imp_df\n",
    "\n",
    "def calculate_permutation_importance(model, X_val, y_val, top_n=50):\n",
    "    \"\"\"Calculates and plots permutation importance\"\"\"\n",
    "    print(\"Calculating permutation importance...\")\n",
    "    scorer = make_scorer(average_f1_score, needs_proba=True)\n",
    "    \n",
    "    result = permutation_importance(\n",
    "        model, X_val, y_val, n_repeat=5, random_state=SEED, n_jobs=-1, scoring=scorer\n",
    "    )\n",
    "    \n",
    "    perm_imp_df = pd.DataFrame({\n",
    "        'feature': X_val.columns,\n",
    "        'importance_mean': result.importances_mean,\n",
    "        'importances_std': result.importances_std,\n",
    "    }).sort_values('importance_mean', ascending=False).head(top_n)\n",
    "    \n",
    "    print(\"Top 10 Permutation Importances:\\n\", perm_imp_df.head(10))\n",
    "    \n",
    "    plt.figure(figsize=(12, top_n / 2))\n",
    "    plt.barh(\n",
    "        perm_imp_df['feature'],\n",
    "        perm_imp_df['importance_mean'],\n",
    "        xerr=perm_imp_df['importance_std'],\n",
    "        align='center'\n",
    "    )\n",
    "    plt.title(f'Top {top_n} Features (Permutation Importance on Validation Set)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return perm_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83b04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
